## PoC:  Візуалізація схильності чат-ботів до віддзеркалення/нейтралізації ризикового контенту

### Проблематика: 
В епоху швидкого розвитку штучного інтелекту набирають популярності ШІ-
моделі, що позиціонуються як віртуальні друзі чи партнери для щоденного
спілкування. Найвідоміші приклади – Character.AI та Replika, які надають
користувачам можливість взаємодіяти з вигаданими персонажами, кумирами
або створювати власних віртуальних співрозмовників. Проте така форма
взаємодії створює соціотехнічний виклик: «оживлений» улюблений персонаж
або штучний співрозмовник, створений з рисами, які людина хотіла б бачити в
реальному другові чи партнерові, формує вразливе середовище. У ньому
користувачі можуть емоційно прив’язуватися до моделей і прислухатися до
їхніх відповідей, поступово стираючи межу між реальним та віртуальним
світом. Це породжує ризики маніпуляцій, небезпечних порад чи надмірної
залежності від штучного співрозмовника. 

### Чому саме така ідея для PoC?
Ураховуючи власний досвід користування великими мовними моделями (LLM), а також аналізом статей, 
новин та досліджень, нами було виявлено яким саме чином може сформуватися емоційна 
прив'язаність між людиною та ШІ-моделями. 

**Механізм емоційного віддзеркалення**. Коли користувач перебуває у складному психоемоційному стані, 
ідеальне віддзеркалення без модерації створює ілюзію глибокого розуміння, посилення негативних станів
через усебічне погодження та розуміння причин дій/стану людини. 

Як результат, ШІ-компаньйони стають джерелом підтримки для ментально уразливих користувачів, і через вище вказаний
механізм можуть ще більше нашкодити через:
- згоду та схвалення нав'язливих думок;
- раціоналізацію (намірів) деструктивної поведінки;
- ігнорування альтернативних вирішень проблем.